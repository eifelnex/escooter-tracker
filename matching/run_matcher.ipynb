{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6449a025",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nfrom pathlib import Path\n\nsys.path.insert(0, str(Path().resolve().parent))\n\nfrom matching_pipeline import run_pipeline, load_all_candidates\n\nsummary = run_pipeline(events_path=\"../vehicle_events_export.parquet\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b860d7a9",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nfrom pathlib import Path\nimport psutil\nimport os\n\ndef optimize_dtypes(df):\n    df['d_idx'] = df['d_idx'].astype('int32')\n    df['f_idx'] = df['f_idx'].astype('int32')\n    \n    float_cols = ['d_lat', 'd_lon', 'f_lat', 'f_lon', 'd_range_km', 'f_range_km',\n                  'range_consumed', 'delta_t_hours', 'opt_route_km', 'opt_route_min',\n                  'speed', 'log_p_distance', 'log_p_speed', 'log_p_range', 'score']\n    for col in float_cols:\n        if col in df.columns:\n            df[col] = df[col].astype('float32')\n    \n    df['provider'] = df['provider'].astype('category')\n    df['vehicle_type_id'] = df['vehicle_type_id'].astype('category')\n    return df\n\nfiles = list(Path(\"matching_output/candidates\").glob(\"*_candidates.parquet\"))\n\ndfs = []\nfor file in files:\n    df = optimize_dtypes(pd.read_parquet(file))\n    dfs.append(df)\n\nall_candidates = pd.concat(dfs, ignore_index=True)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3aeb1",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\n\ndef bidirectional_assignment_fast(candidates, n_iterations=3, forward_temp=1.0, backward_temp=3.0, null_score=-15):\n    candidates = candidates.copy()\n    scores = candidates['score'].values.copy()\n    \n    d_groups = candidates.groupby('d_idx').ngroup().values\n    f_groups = candidates.groupby('f_idx').ngroup().values\n    n_d_groups = d_groups.max() + 1\n    n_f_groups = f_groups.max() + 1\n    \n    score_adj = scores.copy()\n    \n    for iteration in range(n_iterations):\n        s_fwd = score_adj / forward_temp\n        max_d = np.full(n_d_groups, -np.inf)\n        np.maximum.at(max_d, d_groups, s_fwd)\n        max_d = np.maximum(max_d, null_score / forward_temp)\n        \n        exp_s = np.exp(s_fwd - max_d[d_groups])\n        exp_null = np.exp(null_score / forward_temp - max_d)\n        \n        sum_d = np.zeros(n_d_groups)\n        np.add.at(sum_d, d_groups, exp_s)\n        sum_d += exp_null\n        \n        prob_forward = exp_s / sum_d[d_groups]\n        prob_null = exp_null / sum_d\n        \n        s_back = score_adj / backward_temp\n        max_f = np.full(n_f_groups, -np.inf)\n        np.maximum.at(max_f, f_groups, s_back)\n        \n        exp_s_back = np.exp(s_back - max_f[f_groups])\n        sum_f = np.zeros(n_f_groups)\n        np.add.at(sum_f, f_groups, exp_s_back)\n        \n        prob_backward = exp_s_back / sum_f[f_groups]\n        \n        if iteration < n_iterations - 1:\n            penalty = -np.log(np.maximum(prob_backward, 1e-6))\n            score_adj = scores - penalty\n    \n    candidates['prob_forward'] = prob_forward\n    candidates['prob_backward'] = prob_backward\n    candidates['prob_null'] = prob_null[d_groups]\n    candidates['prob'] = prob_forward\n    \n    return candidates"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217aeb46",
   "metadata": {},
   "outputs": [],
   "source": "df = pd.read_parquet(\"../events_with_flags.parquet\")\n\nNON_COMPLIANT_PROVIDERS = ['lime_zurich', 'lime_stuttgart', 'lime_basel', 'lime_uster', 'lime_opfikon']\n\ntemp_d_idx = df[\n    (df['is_temporary_disappearance'] == True) & \n    (~df['provider'].isin(NON_COMPLIANT_PROVIDERS))\n].index\n\nfiltered = all_candidates[~all_candidates['d_idx'].isin(temp_d_idx)]\n\nresult = bidirectional_assignment_fast(filtered, n_iterations=3, forward_temp=1.0, backward_temp=3.0)\n\nbest_matches = result.loc[result.groupby('d_idx')['prob'].idxmax()]"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea35933",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = result.to_parquet(\"matching_candidates_scored.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vob1wzs2jp",
   "metadata": {},
   "outputs": [],
   "source": "matches = pd.read_parquet(\"matching_output/matching_candidates_scored.parquet\")\ndf = pd.read_parquet(\"../vehicle_events_export.parquet\")\n\ntotal_disappearances = df['disappeared'].sum()\n\nexcluded = df['is_maintenance'] | df['is_id_reset'] | df['is_temporary_disappearance']\nn_excluded = (df['disappeared'] & excluded).sum()\nreal_disappearances = (df['disappeared'] & ~excluded).sum()\n\nn_with_candidates = matches['d_idx'].nunique()\n\nbest_matches = matches.loc[matches.groupby('d_idx')['prob'].idxmax()]\nhigh_conf_matches = best_matches[best_matches['prob'] > 0.5]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cqeiwkehtj4",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\n\ndf = pd.read_parquet(\"../events_with_flags.parquet\")\nmatches = pd.read_parquet(\"matching_output/matching_candidates_scored.parquet\")\n\nexcluded = df['is_maintenance'] | df['is_id_reset'] | df['is_temporary_disappearance']\nreal_disappeared = df[df['disappeared'] & ~excluded].copy()\n\nmatched_d_idx = set(matches['d_idx'].unique())\nreal_disappeared['has_candidate'] = real_disappeared.index.isin(matched_d_idx)\n\nunmatched = real_disappeared[~real_disappeared['has_candidate']]\nmatched = real_disappeared[real_disappeared['has_candidate']]\n\nprovider_stats = real_disappeared.groupby('provider').agg(\n    total=('has_candidate', 'count'),\n    matched=('has_candidate', 'sum')\n)\nprovider_stats['unmatched'] = provider_stats['total'] - provider_stats['matched']\nprovider_stats['match_rate'] = 100 * provider_stats['matched'] / provider_stats['total']\n\nno_range = unmatched['current_range_meters'].isna().sum()\n\nif 'current_range_meters' in unmatched.columns:\n    low_range = (unmatched['current_range_meters'] < 300).sum()\n\nunmatched['hour'] = pd.to_datetime(unmatched['timestamp']).dt.hour\nmatched['hour'] = pd.to_datetime(matched['timestamp']).dt.hour"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qc9m5mgdrwg",
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.neighbors import BallTree\nimport numpy as np\n\nfirst_seen = df[df['first_seen'] & ~excluded].copy()\nfirst_seen = first_seen[first_seen['current_range_meters'].notna()]\n\nsample_size = min(10000, len(unmatched))\nunmatched_sample = unmatched.sample(sample_size, random_state=42)\n\nMAX_TIME_HOURS = 1.0\nMAX_DISTANCE_KM = 8.0\nMIN_RANGE_DRAIN_KM = 0.3\n\nresults = {\n    'no_fs_same_provider_vtype': 0,\n    'no_fs_in_time_window': 0,\n    'no_fs_in_distance': 0,\n    'no_fs_with_range_drain': 0,\n    'has_potential_match': 0,\n}\n\nfor provider in unmatched_sample['provider'].unique():\n    for vtype in unmatched_sample[unmatched_sample['provider'] == provider]['vehicle_type_id'].unique():\n        d_subset = unmatched_sample[\n            (unmatched_sample['provider'] == provider) & \n            (unmatched_sample['vehicle_type_id'] == vtype)\n        ]\n        \n        fs_subset = first_seen[\n            (first_seen['provider'] == provider) & \n            (first_seen['vehicle_type_id'] == vtype)\n        ]\n        \n        if len(fs_subset) == 0:\n            results['no_fs_same_provider_vtype'] += len(d_subset)\n            continue\n        \n        fs_coords = np.radians(fs_subset[['lat', 'lon']].values)\n        tree = BallTree(fs_coords, metric='haversine')\n        \n        d_coords = np.radians(d_subset[['lat', 'lon']].values)\n        d_times = pd.to_datetime(d_subset['timestamp']).values\n        d_ranges = d_subset['current_range_meters'].values / 1000.0\n        \n        fs_times = pd.to_datetime(fs_subset['timestamp']).values\n        fs_ranges = fs_subset['current_range_meters'].values / 1000.0\n        \n        max_dist_rad = MAX_DISTANCE_KM / 6371.0\n        \n        for i in range(len(d_subset)):\n            d_time = d_times[i]\n            d_range = d_ranges[i]\n            \n            neighbors = tree.query_radius([d_coords[i]], r=max_dist_rad)[0]\n            \n            if len(neighbors) == 0:\n                time_mask = (fs_times > d_time) & (fs_times <= d_time + np.timedelta64(int(MAX_TIME_HOURS * 3600), 's'))\n                if time_mask.sum() == 0:\n                    results['no_fs_in_time_window'] += 1\n                else:\n                    results['no_fs_in_distance'] += 1\n                continue\n            \n            found_match = False\n            for j in neighbors:\n                f_time = fs_times[j]\n                f_range = fs_ranges[j]\n                \n                delta_t = (f_time - d_time) / np.timedelta64(1, 'h')\n                if delta_t <= 0 or delta_t > MAX_TIME_HOURS:\n                    continue\n                \n                range_consumed = d_range - f_range\n                if range_consumed >= MIN_RANGE_DRAIN_KM:\n                    found_match = True\n                    break\n            \n            if found_match:\n                results['has_potential_match'] += 1\n            else:\n                results['no_fs_with_range_drain'] += 1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvsplat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}